[2016-11-22 06:47:49,685] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-11-22 06:47:49,690] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-11-22 06:47:49,690] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-11-22 06:47:50,352] INFO re-registering broker info in ZK for broker 0 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-11-22 06:47:50,358] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-11-22 06:47:50,360] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-11-22 06:47:50,361] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(10.13.37.1,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-11-22 06:47:50,361] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-11-22 06:47:50,361] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-11-22 06:47:50,757] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-11-22 06:47:50,759] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,test-0,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,email_one_email_to_be_sent-0,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 (kafka.server.ReplicaFetcherManager)
[2016-11-22 06:48:20,561] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-11-22 06:48:20,566] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-11-22 06:49:16,211] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 06:49:45,742] INFO Rolled new log segment for 'email_one_email_to_be_sent-0' in 37 ms. (kafka.log.Log)
[2016-11-22 06:49:45,744] INFO Scheduling log segment 0 for log email_one_email_to_be_sent-0 for deletion. (kafka.log.Log)
[2016-11-22 06:49:45,754] ERROR Uncaught exception in scheduled task 'kafka-log-retention' (kafka.utils.KafkaScheduler)
kafka.common.KafkaStorageException: Failed to change the log file suffix from  to .deleted for log segment 0
	at kafka.log.LogSegment.kafkaStorageException$1(LogSegment.scala:327)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:329)
	at kafka.log.Log.kafka$log$Log$$asyncDeleteSegment(Log.scala:953)
	at kafka.log.Log.kafka$log$Log$$deleteSegment(Log.scala:943)
	at kafka.log.Log$$anonfun$deleteOldSegments$1.apply(Log.scala:650)
	at kafka.log.Log$$anonfun$deleteOldSegments$1.apply(Log.scala:650)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at kafka.log.Log.deleteOldSegments(Log.scala:650)
	at kafka.log.Log.deleteRetenionMsBreachedSegments(Log.scala:680)
	at kafka.log.Log.deleteOldSegments(Log.scala:674)
	at kafka.log.LogManager$$anonfun$cleanupLogs$3.apply(LogManager.scala:429)
	at kafka.log.LogManager$$anonfun$cleanupLogs$3.apply(LogManager.scala:427)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:427)
	at kafka.log.LogManager$$anonfun$startup$1.apply$mcV$sp(LogManager.scala:191)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:58)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.file.NoSuchFileException: /tmp/kafka-logs/email_one_email_to_be_sent-0/00000000000000000000.log
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixCopyFile.move(UnixCopyFile.java:409)
	at sun.nio.fs.UnixFileSystemProvider.move(UnixFileSystemProvider.java:262)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:670)
	at kafka.log.FileMessageSet.renameTo(FileMessageSet.scala:427)
	... 28 more
	Suppressed: java.nio.file.NoSuchFileException: /tmp/kafka-logs/email_one_email_to_be_sent-0/00000000000000000000.log -> /tmp/kafka-logs/email_one_email_to_be_sent-0/00000000000000000000.log.deleted
		at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
		at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
		at sun.nio.fs.UnixCopyFile.move(UnixCopyFile.java:396)
		at sun.nio.fs.UnixFileSystemProvider.move(UnixFileSystemProvider.java:262)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:667)
		... 29 more
[2016-11-22 06:54:45,724] INFO Rolled new log segment for 'test-0' in 30 ms. (kafka.log.Log)
[2016-11-22 06:54:45,725] INFO Scheduling log segment 0 for log test-0 for deletion. (kafka.log.Log)
[2016-11-22 06:54:45,726] ERROR Uncaught exception in scheduled task 'kafka-log-retention' (kafka.utils.KafkaScheduler)
kafka.common.KafkaStorageException: Failed to change the log file suffix from  to .deleted for log segment 0
	at kafka.log.LogSegment.kafkaStorageException$1(LogSegment.scala:327)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:329)
	at kafka.log.Log.kafka$log$Log$$asyncDeleteSegment(Log.scala:953)
	at kafka.log.Log.kafka$log$Log$$deleteSegment(Log.scala:943)
	at kafka.log.Log$$anonfun$deleteOldSegments$1.apply(Log.scala:650)
	at kafka.log.Log$$anonfun$deleteOldSegments$1.apply(Log.scala:650)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at kafka.log.Log.deleteOldSegments(Log.scala:650)
	at kafka.log.Log.deleteRetenionMsBreachedSegments(Log.scala:680)
	at kafka.log.Log.deleteOldSegments(Log.scala:674)
	at kafka.log.LogManager$$anonfun$cleanupLogs$3.apply(LogManager.scala:429)
	at kafka.log.LogManager$$anonfun$cleanupLogs$3.apply(LogManager.scala:427)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:427)
	at kafka.log.LogManager$$anonfun$startup$1.apply$mcV$sp(LogManager.scala:191)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:58)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.file.NoSuchFileException: /tmp/kafka-logs/test-0/00000000000000000000.log
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixCopyFile.move(UnixCopyFile.java:409)
	at sun.nio.fs.UnixFileSystemProvider.move(UnixFileSystemProvider.java:262)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:670)
	at kafka.log.FileMessageSet.renameTo(FileMessageSet.scala:427)
	... 28 more
	Suppressed: java.nio.file.NoSuchFileException: /tmp/kafka-logs/test-0/00000000000000000000.log -> /tmp/kafka-logs/test-0/00000000000000000000.log.deleted
		at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
		at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
		at sun.nio.fs.UnixCopyFile.move(UnixCopyFile.java:396)
		at sun.nio.fs.UnixFileSystemProvider.move(UnixFileSystemProvider.java:262)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:667)
		... 29 more
[2016-11-22 06:59:16,194] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
